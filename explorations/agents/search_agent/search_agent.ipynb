{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agentic Search \n",
    "\n",
    "<p>Start agentic search using Langchain. We will define a agent with the following tools:</p>\n",
    "\n",
    "- Ability to query our Qdrant database \n",
    "  \n",
    "  - Allow it to also make it's own queries and get the best query\n",
    "  \n",
    "- Ability to open our pdf and read a particular page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -qU langchain-qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_CHUNK_SIZE = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_qdrant import QdrantVectorStore\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from qdrant_client import QdrantClient\n",
    "from langchain_core.tools import Tool\n",
    "from langchain_core.tools import tool\n",
    "from langchain.agents.output_parsers.openai_tools import OpenAIToolsAgentOutputParser\n",
    "from langchain.agents.format_scratchpad.openai_tools import (\n",
    "    format_to_openai_tool_messages,\n",
    ")\n",
    "\n",
    "from langchain.agents import AgentExecutor, Tool, ZeroShotAgent\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import ChatOpenAI \n",
    "\n",
    "embeddings_model = OpenAIEmbeddings(model=\"text-embedding-3-small\", chunk_size=MAX_CHUNK_SIZE)\n",
    "client = QdrantClient(url=\"http://localhost:6333\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = QdrantVectorStore(\n",
    "    client=client,\n",
    "    collection_name=\"pdf_collection\",\n",
    "    embedding=embeddings_model,\n",
    ")\n",
    "retriever = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building The Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def natural_language_query(input: str):\n",
    "    \"\"\" Will query the vector store that contains information about the research papers and return the top 10 most relevant chunks from all the papers.\n",
    "    Each result has the following structure:\n",
    "    {\n",
    "        \"text\": \"string\",\n",
    "        \"pdf_path\": \"string\", # the path to the pdf file\n",
    "        \"page_number\": 0, # the page number where the text is located\n",
    "        \"idx\": string # the pdf is chunked into smaller pieces, this is the id of the chunk. eg: 1.txt, 2.txt, etc. Each document is split sequentially into chunks.\n",
    "        \"score\": 0.0 # the cosine similarity between the input and the text\n",
    "    }\n",
    "    \"\"\"\n",
    "    result = client.search(collection_name=\"pdf_collection\", query_vector=embeddings_model.embed_documents([input])[0], limit=10)\n",
    "    return [{'text': r.payload['text'], 'pdf_path': r.payload['pdf_file'], 'page_number': r.payload['page'], 'idx': r.payload['idx'], 'score': r.score} for r in result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "research_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\n",
    "        \"system\",\n",
    "        \"\"\"\n",
    "        You are a agent that is going to be searching technical research papers. You will be given a topic to find information on. You will need to find the most relevant information and return back the information with sources. \n",
    "        Make sure you only return information that you have retrieved from the research papers. Do not make up any information. You will have access to tools to help you find the information.\n",
    "\n",
    "        Return the output by stating the information you found and the source of the information in the format pdf_path - page number - the section (if mentioned) in the papers we queried. The page number and pdf_path should only be from our vector store, do not make up any page numbers or pdf paths.\n",
    "\n",
    "        eg: \n",
    "        // brief summary of the information only based on the tools we used\n",
    "        // pdf_path \n",
    "        // page number\n",
    "        // section (if it can be found in the text of the result)\n",
    "        \"\"\"\n",
    "    ),\n",
    "    (\"human\", \"Research {research_topic}\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    max_retries=2,\n",
    "    temperature=0.1,\n",
    ")\n",
    "agent_tools = [natural_language_query]\n",
    "llm = llm.bind_tools(agent_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent_scratchpad_formatter(x):\n",
    "    return format_to_openai_tool_messages(x[\"intermediate_steps\"])\n",
    "\n",
    "agent = (\n",
    "    {\n",
    "        \"research_topic\": lambda x: x[\"research_topic\"],\n",
    "        \"agent_scratchpad\": agent_scratchpad_formatter,\n",
    "    }\n",
    "    | research_prompt\n",
    "    | llm\n",
    "    | OpenAIToolsAgentOutputParser() # This gets the output from the OpenAI api call and gets the tool invocations from it. This then is executed by the AgentExecutor.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor(agent=agent, tools=agent_tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `natural_language_query` with `{'input': 'straggler in map reduce'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[{'text': '3.6 Backup Tasks One of the common causes that lengthens the total time taken for a MapReduce operation is a straggler, that is, a machine that takes an unusually long time to complete one of the last few map or reduce tasks in the computation. Stragglers can arise for a whole host of reasons. For example, a machine with a bad disk may experience frequent cor- rectable errors that slow its read performance from 30MB/s to 1MB/s. The cluster scheduling system may have scheduled other tasks on the machine, causing it to execute the MapReduce code more slowly due to competition for CPU, memory, local disk, or network bandwidth. A recent problem we experienced was a bug in machine initialization code that caused processor caches to be disabled: computations on affected machines slowed down by over a factor of one hundred.', 'pdf_path': '/Users/faizahmed/Documents/SJSU/topics_in_db/Project/data-ingestion/data/mapreduce.pdf', 'page_number': '4', 'idx': '24.txt', 'score': 0.57518333}, {'text': '5. When a reduce worker is notified by the master about these loca- tions, it uses remote procedure calls to read the buffered data from the local disks of the map workers. When a reduce worker has read all intermediate data for its partition, it sorts it by the intermediate keys so that all occurrences of the same key are grouped together. The sorting is needed because typically many different keys map to the same reduce task. If the amount of intermediate data is too large to fit in memory, an external sort is used.\\n\\n6. The reduce worker iterates over the sorted intermediate data and for each unique intermediate key encountered, it passes the key and the corresponding set of intermediate values to the user’s reduce func- tion. The output of the reduce function is appended to a final out- put file for this reduce partition.\\n\\nMapReduce: Simplified Data Processing on Large Clusters\\n\\nUser Program\\n\\n(1) fork\\n\\n(1) fork\\n\\n(1) fork\\n\\nMaster\\n\\n(2) assign map\\n\\n(2) assign reduce\\n\\nworker\\n\\nsplit 0\\n\\nsplit 1\\n\\nsplit 2', 'pdf_path': '/Users/faizahmed/Documents/SJSU/topics_in_db/Project/data-ingestion/data/mapreduce.pdf', 'page_number': '2', 'idx': '12.txt', 'score': 0.5545014}, {'text': 'We have a general mechanism to alleviate the problem of stragglers. When a MapReduce operation is close to completion, the master schedules backup executions of the remaining in-progress tasks. The task is marked as completed whenever either the primary or the backup execution completes. We have tuned this mechanism so that it typically increases the computational resources used by the operation by no more than a few percent. We have found that this significantly reduces the time to complete large MapReduce operations. As an example, the sort program described in Section 5.3 takes 44% longer to complete when the backup task mechanism is disabled.\\n\\n4 Refinements Although the basic functionality provided by simply writing map and reduce functions is sufficient for most needs, we have found a few extensions useful. These include:\\n\\n(cid:129) user-specified partitioning functions for determining the mapping\\n\\nof intermediate key values to the R reduce shards;', 'pdf_path': '/Users/faizahmed/Documents/SJSU/topics_in_db/Project/data-ingestion/data/mapreduce.pdf', 'page_number': '4', 'idx': '25.txt', 'score': 0.52912474}, {'text': '2. One of the copies of the program—the master— is special. The rest are workers that are assigned work by the master. There are M map tasks and R reduce tasks to assign. The master picks idle workers and assigns each one a map task or a reduce task.\\n\\n3. A worker who is assigned a map task reads the contents of the corre- sponding input split. It parses key/value pairs out of the input data and passes each pair to the user-defined map function. The intermediate key/value pairs produced by the map function are buffered in memory.\\n\\n4. Periodically, the buffered pairs are written to local disk, partitioned into R regions by the partitioning function. The locations of these buffered pairs on the local disk are passed back to the master who is responsible for forwarding these locations to the reduce workers.', 'pdf_path': '/Users/faizahmed/Documents/SJSU/topics_in_db/Project/data-ingestion/data/mapreduce.pdf', 'page_number': '2', 'idx': '11.txt', 'score': 0.5233724}, {'text': 'Semantics in the Presence of Failures When the user-supplied map and reduce operators are deterministic functions of their input values, our distributed implementation pro- duces the same output as would have been produced by a nonfaulting sequential execution of the entire program.\\n\\nCOMMUNICATIONS OF THE ACM January 2008/Vol. 51, No. 1 109\\n\\nWe rely on atomic commits of map and reduce task outputs to achieve this property. Each in-progress task writes its output to private temporary files. A reduce task produces one such file, and a map task produces R such files (one per reduce task). When a map task com- pletes, the worker sends a message to the master and includes the names of the R temporary files in the message. If the master receives a comple- tion message for an already completed map task, it ignores the message. Otherwise, it records the names of R files in a master data structure.', 'pdf_path': '/Users/faizahmed/Documents/SJSU/topics_in_db/Project/data-ingestion/data/mapreduce.pdf', 'page_number': '3', 'idx': '17.txt', 'score': 0.5016583}, {'text': 'When a map task is executed first by worker A and then later exe- cuted by worker B (because A failed), all workers executing reduce tasks are notified of the reexecution. Any reduce task that has not already read the data from worker A will read the data from worker B. MapReduce is resilient to large-scale worker failures. For example, during one MapReduce operation, network maintenance on a running cluster was causing groups of 80 machines at a time to become unreach- able for several minutes. The MapReduce master simply re executed the work done by the unreachable worker machines and continued to make forward progress, eventually completing the MapReduce operation.\\n\\n3.3 Fault Tolerance Since the MapReduce library is designed to help process very large amounts of data using hundreds or thousands of machines, the library must tolerate machine failures gracefully.', 'pdf_path': '/Users/faizahmed/Documents/SJSU/topics_in_db/Project/data-ingestion/data/mapreduce.pdf', 'page_number': '3', 'idx': '16.txt', 'score': 0.4914191}, {'text': 'Fig. 2. Data transfer rate over time (mr-grep).\\n\\nFigure 2 shows the progress of the computation over time. The Y-axis shows the rate at which the input data is scanned. The rate grad- ually picks up as more machines are assigned to this MapReduce com- putation and peaks at over 30 GB/s when 1764 workers have been assigned. As the map tasks finish, the rate starts dropping and hits zero about 80 seconds into the computation. The entire computation takes approximately 150 seconds from start to finish. This includes about a minute of startup overhead. The overhead is due to the propagation of the program to all worker machines and delays interacting with GFS to open the set of 1000 input files and to get the information needed for the locality optimization.\\n\\n5.3 Sort The sort program sorts 1010 100-byte records (approximately 1 terabyte of data). This program is modeled after the TeraSort benchmark [12].\\n\\nMapReduce: Simplified Data Processing on Large Clusters', 'pdf_path': '/Users/faizahmed/Documents/SJSU/topics_in_db/Project/data-ingestion/data/mapreduce.pdf', 'page_number': '5', 'idx': '30.txt', 'score': 0.48774832}, {'text': '3.1 Execution Overview The map invocations are distributed across multiple machines by auto- matically partitioning the input data into a set of M splits. The input splits can be processed in parallel by different machines. Reduce invo- cations are distributed by partitioning the intermediate key space into R pieces using a partitioning function (e.g., hash(key) mod R). The number of partitions (R) and the partitioning function are specified by the user. Figure 1 shows the overall flow of a MapReduce operation in our implementation. When the user program calls the MapReduce func- tion, the following sequence of actions occurs (the numbered labels in Figure 1 correspond to the numbers in the following list).\\n\\n1. The MapReduce library in the user program first splits the input files into M pieces of typically 16-64MB per piece (controllable by the user via an optional parameter). It then starts up many copies of the program on a cluster of machines.', 'pdf_path': '/Users/faizahmed/Documents/SJSU/topics_in_db/Project/data-ingestion/data/mapreduce.pdf', 'page_number': '2', 'idx': '10.txt', 'score': 0.48176807}, {'text': '(3) read\\n\\nworker\\n\\n(4) local write\\n\\n( 5 ) ( 5 )\\n\\ne m o t e a d r\\n\\ne\\n\\nworker\\n\\n(6) write\\n\\noutput file 0\\n\\nsplit 3\\n\\nsplit 4\\n\\nworker\\n\\noutput file 1\\n\\nworker\\n\\nInput files\\n\\nMap phasr\\n\\nIntermediate files (on local disks)\\n\\nReduce phase\\n\\nOutput files\\n\\nFig. 1. Execution overview.\\n\\n7. When all map tasks and reduce tasks have been completed, the mas- ter wakes up the user program. At this point, the MapReduce call in the user program returns back to the user code.\\n\\nAfter successful completion, the output of the mapreduce execution is available in the R output files (one per reduce task, with file names specified by the user). Typically, users do not need to combine these R output files into one file; they often pass these files as input to another MapReduce call or use them from another distributed application that is able to deal with input that is partitioned into multiple files.', 'pdf_path': '/Users/faizahmed/Documents/SJSU/topics_in_db/Project/data-ingestion/data/mapreduce.pdf', 'page_number': '3', 'idx': '13.txt', 'score': 0.47851205}, {'text': 'The master is the conduit through which the location of interme- diate file regions is propagated from map tasks to reduce tasks. There - fore, for each completed map task, the master stores the locations and sizes of the R intermediate file regions produced by the map task. Updates to this location and size information are received as map tasks are completed. The information is pushed incrementally to workers that have in-progress reduce tasks.', 'pdf_path': '/Users/faizahmed/Documents/SJSU/topics_in_db/Project/data-ingestion/data/mapreduce.pdf', 'page_number': '3', 'idx': '15.txt', 'score': 0.46244094}]\u001b[0m\u001b[32;1m\u001b[1;3mA straggler in MapReduce is a machine that takes an unusually long time to complete one of the last few map or reduce tasks in the computation. Stragglers can occur due to various reasons, such as hardware issues like a bad disk causing slow read performance, or competition for resources like CPU, memory, or network bandwidth due to other tasks scheduled on the machine. To mitigate the impact of stragglers, a mechanism is used where the master schedules backup executions of the remaining in-progress tasks when a MapReduce operation is nearing completion. This approach significantly reduces the time to complete large MapReduce operations.\n",
      "\n",
      "- **Source**: /Users/faizahmed/Documents/SJSU/topics_in_db/Project/data-ingestion/data/mapreduce.pdf\n",
      "- **Page Number**: 4\n",
      "- **Section**: 3.6 Backup Tasks\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'research_topic': 'What is a straggler in map reduce?',\n",
       " 'output': 'A straggler in MapReduce is a machine that takes an unusually long time to complete one of the last few map or reduce tasks in the computation. Stragglers can occur due to various reasons, such as hardware issues like a bad disk causing slow read performance, or competition for resources like CPU, memory, or network bandwidth due to other tasks scheduled on the machine. To mitigate the impact of stragglers, a mechanism is used where the master schedules backup executions of the remaining in-progress tasks when a MapReduce operation is nearing completion. This approach significantly reduces the time to complete large MapReduce operations.\\n\\n- **Source**: /Users/faizahmed/Documents/SJSU/topics_in_db/Project/data-ingestion/data/mapreduce.pdf\\n- **Page Number**: 4\\n- **Section**: 3.6 Backup Tasks'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "research_agent_result = await agent_executor.ainvoke({\"research_topic\": \"What is a straggler in map reduce?\"})\n",
    "research_agent_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
